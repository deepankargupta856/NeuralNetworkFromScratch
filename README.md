# ðŸ§  Built Neural Networks from Scratch

A lightweight, NumPy-based neural network library built from scratch to boost understanding of the internal mechanics of deep learning. It replicates core concepts of popular libraries like Keras or PyTorch â€” but without the abstraction, offering full visibility into every forward and backward pass.

---

## ðŸ“Œ Key Features

- âœ… Dense (fully connected) layers  
- âœ… Activation functions: ReLU, Softmax  
- âœ… Combined Softmax + Categorical Crossentropy for numerical stability  
- âœ… Dropout regularization  
- âœ… L1 & L2 Regularization  
- âœ… Optimizers: SGD, Adam  
- âœ… Train/test loop with batch support  
- âœ… Spiral dataset generator  
- ðŸ§ª Easily extendable with custom layers, losses, and metrics  

---



